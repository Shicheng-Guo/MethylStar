---
title: "Methylation analysis of WGBS data"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

To process a large number of WGBS samples in a consistent, documented and reproducible manner it is advisable to use a pipeline system. Here our pipeline comprises of custom bash scripts together with pre-installed softwares such as:

(1) Trimmomatic-0.36 : A flexible read trimming tool (Java based) for Illumina NGS data

(2) Bismark-v0.19.0 : Bismark is a program to map bisulfite treated sequencing reads to a genome of interest (in our case Arabidopsis thaliana) and perform methylation calls. Bisulfite treated reads are mapped using the short read aligner Bowtie 2, and  therefore it  is  a  requirement  that  Bowtie 1 or  Bowtie  2 are also installed on your machine. Bismark also requires SAMtools to be pre-installed on the computer.

(3) Bowtie 1.2.2: An ultrafast, memory-efficient short read aligner.
(4) FastQC : A Java based quality control tool for high throughput sequence data.

(5) Methimpute: A R package for imputation of DNA methylation from WGBS data
(6) SAMtools : Samtools is a suite of programs for interacting with high-throughput sequencing data

### Configuration file for pipeline
The following script contains configuration parameters for running the pipeline.

<config.cfg>

(1) set base directory with PATH of raw datasets:

```{bash}
##The result directory, for Trimmomatic files/log files/ QC-reporting , etc.
result_pipeline="/home/work_dir"

## Directory of data-sets (RAW files)
## The format of our input files are fastq
raw_dataset="/home/raw_datasets"
```

(2) specify Trimmomatic parameters:

```{bash}
##Number of threads
n_th=16

##Directory of Adapters
dir_adap="/usr/share/Trimmomatic-0.36/adapters"

##name of adapter
name_adap="TruSeq3-SE.fa"
```

(3) specify parameters for running Bismark mapper:

```{bash}
# ref.genome directory
genome_ref="/home/shared/reference_genome"
genome_name="TAIR10_chr_all.fa"

# set number of cores for parallel processing
bis_parallel=32

# Nucleotide coverage
nucleotide=FALSE
```

### Run entire pipeline or as individual modules

<run.sh>

Run whole pipeline with the following jobs or run them as individual scripts

```{bash}
job0="preparing.sh"
job1="trimmomatic.sh"
job2="qc-fastq-report.sh"
job3="bismark-mapper.sh"
job4="qc-bam-report.sh"
job5="bismark-deduplicate.sh"
job6="bismark-meth-extractor.sh"
job7="methimpute.sh"

```

Start the pipleine by making sure specific PATHs to reference genome and output folders exist

<preparing.sh>

```{bash}
# check if the user input directory exist
if [ ! -d $raw_dataset ]; then
	echo "Directory of data-sets do not exist. see the configuration file 'config.cfg'"
	exit 1
fi

# create new directories for fqfiles, fq-logs, qc-fastqc-report, bismark-mapper, qc-bam-report, bismark-desduplicate, bismark-meth-extractor
# Here is an example to make a folder for output fasta files 'tmp_fq'
if [ ! -d $tmp_fq ]; then
	mkdir $tmp_fq
fi
```

### Run Trimmomatic

<trimmomatic.sh>

specify the following parameters for trimming the FASTQ reads

(a) single end reads
(b) no. of threads
(b) convert quality scores to phred33
(c) ILLUMINACLIP::::for e.g TruSeq3-SE.fa:1:30:9
(d) Remove leading low quality or N bases (below quality 20) (LEADING:20)
(e) Remove trailing low quality or N bases (below quality 20) (TRAILING:20)
(f) SLIDINGWINDOW:: Perform a sliding window trimming, cutting once the average quality within the window falls below a threshold. for e.g SLIDINGWINDOW: 4:20
(g) Drop the read if it is below a specified length for e.g MINLEN:36

Now, run Trimmomatic for all files within the folder using parallel mode:
write logs to 'tmp_log'

```{bash}
for folder in $raw_dataset
do
    (cd "$raw_dataset" &&
		# calc time of process for each file
		start=$(date +%s)
		echo "----------------------------------------------"
		echo "running trimmomatic.... "
		parallel "java -jar /usr/local/bin/trimmomatic-0.36.jar SE -threads
		$n_th -phred33  {1} $tmp_fq/{1}.fq.gz ILLUMINACLIP:$dir_adap/$name_adap:1:30:9
		LEADING:20 TRAILING:20 SLIDINGWINDOW:4:20 MINLEN:36
		2>&1 | tee -a $tmp_log/trimmomatic-log-{1}.log" ::: `ls *.gz`
		end=$(date +%s)
		runtime=$((($(date +%s)-$start)/60))
		echo "Trimmomatic finished. Duration $runtime Minutes."
		echo "-----------------------------------------------" 		
		)
done

# rename files and logs to fq
```

### Pre Alignment quality control

<qc-fastq-report.sh>

Running fastQC on the trimmed fastq files provide a comprehensive assessment of the sequencing quality and any remaining adapter contamination

    fastqc --noextract -f fastq $fq -o $tmp_qcfast

### Alignment using Bismark Mapper  

<bismark-mapper.sh>

(1) Create Bisulfite genome for the first time using the following command

A typical genome indexing looks like this:

    /bismark/bismark_genome_preparation --path_to_bowtie  /usr/local/bowtie/ --verbose $genome_ref

Start running bismark mapper on all the trimmed files using the following parameters:

(1) -s/--skip : Skip (i.e. do not align) the first <int> reads or read pairs from the input.
(2) -u/--upto : Only aligns the first <int> reads or read pairs from the input. Default: no limit.
(3) -n/--seedmms : The maximum number of mismatches permitted in the "seed"
(4) -l/--seedlen : seedlength set as 20
(5) use parallel
(6) --nucleotide_coverage : Calculates the mono- and di-nucleotide sequence composition of covered positions in the analysed BAM file and compares it to the genomic average composition once alignments are complete by calling 'bam2nuc'.
(7) --genome

A typical bismark command looks like this:

      bismark -s 0 -u 0 -n 0 -l 20 --parallel $bis_parallel --nucleotide_coverage --genome $genome_ref -q $fq -o $tmp_bismap

### Post Alignment quality control

<qc-bam-report.sh>

FASTQC is primarily for pre-alignment and it takes as input FASTQ or FASTA files. We have generated aligned files in BAM format. Here we will run fastQC on the BAM files to have a quick overview of any problems with the aligned files.

### Run bismark deduplicate

<bismark-deduplicate.sh>

Bismark includes tools for deduplication, based on identical genomic mapping.
This tool is supposed to remove alignments to the same position in the genome from the Bismark mapping output (both single and paired-end files), which can arise by e.g. excessive PCR amplification. If sequences align to the same genomic position but on different strands they will be scored individually.

Run deduplicate_bismark using the following parameters:

(1) -s/--single : deduplicate single-end Bismark files
(2) --bam : output will be written in BAM format

        deduplicate_bismark -s --bam $bam --output_dir $tmp_dide

### Bismark methylation extractor

<bismark-meth-extractor.sh>

A command to extract context-dependent (CpG/CHG/CHH) methylation. Bismark comes packaged with its own methylation extractor, with the ability to call methylation in all cytosine contexts,  not just CpG. Also a variety of reports,  and levels of verbosity can be specified.

start the run with following parameters:

(1) -s/--single : input files are from single-end read data
(2) --bedGraph : After finishing the methylation extraction, the methylation output is written into a sorted bedGraph file that reports the position of a given cytosine and its methylation state
(3) --CX/--CX_context : The sorted bedGraph output file contains information on every single cytosine that was covered in the experiment irrespective of its sequence context.
(4) --cytosine_report : After the conversion to bedGraph has completed, the option '--cytosine_report' produces a genome-wide methylation report for all cytosines in the genome.
(5) use --parallel
(6) --buffer_size : This allows you to specify the main memory sort buffer when sorting the methylation information.
(7) specify --genome_folder

        bismark_methylation_extractor -s --bedGraph --CX --cytosine_report --parallel $bis_parallel --buffer_size 20G --genome_folder $genome_ref $bm -o $tmp_dme

### A sample bismark_methylation_extractor output

```{r echo=FALSE}
CXfile <- read.table("/home/rashmi/arabidopsis_bismark.txt", sep="\t")
head(CXfile)
```

### Run Methimpute

<methimpute.R>

Impute DNA methylation from WGBS data. Methimpute implements a powerful HMM-based binomial test for methylation status calling. Besides improved accuracy over the classical binomial test, the HMM allows imputation of the methylation status of all cytosines in the genome. It achieves this by borrowing information from neighboring covered cytosines. The confidence in the methylation status call is reported as well. Methimpute also outputs context-specific conversion rates, which might be used to optimize the experimental procedure.

load required packages

Running Methimpute on a list of files generated after running bismark_methylation_extractor

```{r}
library(methimpute)

#set working directory
wd="/home/mydir"
print(wd)

# data import
# data frame with chr lengths
data(arabidopsis_chromosomes)
arabidopsis_chromosomes$chromosome <-sub('chr', '', arabidopsis_chromosomes$chromosome)

#list files
filenames <-list.files(system.file('extdata/testdir', package = 'methimpute'), full.names = TRUE)
#read reference fasta
fasta.file <-system.file("extdata", "TAIR10_chr_all.fa", package = "methimpute")
#extract Cytosines from reference fasta
cytosine.positions <-extractCytosinesFromFASTA(fasta.file, contexts = c('CG', 'CHG', 'CHH'))

CXfiles <- lapply(
  filenames, function(file) {
  name <- gsub(pattern = "\\_.*", "", basename(file))
  bismark.data <-importBismark(file, chrom.lengths = arabidopsis_chromosomes)
  #we need to inflate the data to include all cytosines
  methylome <- inflateMethylome(bismark.data, cytosine.positions)

  # The correlation of methylation levels between neighboring cytosines is an important
  # parameter for the methylation status calling
  # The interacting  context model runs a single HMM for all contexts
  distcor <- distanceCorrelation(methylome)
  fit <- estimateTransDist(distcor)

  #Methylation status calling (and imputation) ===== #
  #model <- callMethylation(data = methylome, transDist = fit$transDist)

  #use exportMethylome function to export data into tsv format
  })
```
### A sample Methimpute output

```{r echo=FALSE}
methout <- read.table("/home/rashmi/sample.txt", sep="\t", header=T)
head(methout)
```
